{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "導入各個套件，切詞、ROUGE、BLEU、sentence transformers、csv...等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Serious\\Program\\venvs\\noodle_LLM\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import csv, os\n",
    "import jieba\n",
    "from rouge_chinese import Rouge\n",
    "from opencc import OpenCC\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 參數選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"lora_type2-8-50E64B_B\",\n",
    "\"lora_type2-8-100E64B_B\",\n",
    "\"lora_type2-128-50E64B_B\",\n",
    "\"lora_type2-128-100E64B_B\",\n",
    "\"lora_type2-256-50E64B_B\",\n",
    "\"lora_type2-256-100E64B_B\",\n",
    "\"lora_type3-256-100E32B_B\",\n",
    "\"lora_type3-256-100E64B_B_old\",\n",
    "\"lora_type3-256-100E64B_2_B\",\n",
    "\"lora_type3-256-100E128B_B\",\n",
    "\"lora_type3-256-150E32B_B\",\n",
    "\"lora_type3-256-200E32B_B\",\n",
    "\"lora_type3-256-200E64B_B\",\n",
    "\"lora_type3-256-200E128B_B\",\n",
    "\"lora_type3-256-200E128B_2_B\",\n",
    "\"lora_type3-256-300E32B_B\",\n",
    "\"lora_type3-256-300E64B_B\",\n",
    "\"lora_type3-256-300E128B_B\",\n",
    "\n",
    "type_list = [\"type2_B\", \"type3_B\"]\n",
    "model_list = [\n",
    "\"lora_type3-256-300E32B_B\",\n",
    "\"lora_type3-256-300E64B_B\",\n",
    "\"lora_type3-256-300E128B_B\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type2_B user values: ['請問你是什麼人？', '什麼是大呷麵本家？', '我在哪裡？', '請問大呷麵本家在哪裡？', '請問大呷麵本家的電話是多少？', '請問大呷麵本家的電子郵件，我想連絡你們？', '你們是叫大甲面本家這個名字嗎？', '你們為什麼不要叫做大甲麵本家？', '大呷麵本家英文名字是什麼？', '大呷麵本家有得到什麼國際認證？', '大呷麵本家是如何製麵的？', '為什麼要用機械化產線，有哪些好處？', '請問鹽水間是幹嘛的？', '請問調製完鹽水然後要幹嘛？', '請問每次製麵時使用多少麵粉？', '麵糰混合完成的下一步是什麼？', '要怎麼製作特殊口味的麵條？', '攪拌麵團的時間怎麼確定的？', '混和好口味的麵糰下一步是什麼？', '麵餅厚度如何控制？', '要怎麼避免麵條變得太厚？', '要怎麼避免麵條變得太薄？', '把麵餅壓製好後下一步是什麼？', '麵餅要怎麼分條？', '一共有哪些規格的麵條？', '製成麵餅後用什麼工具分條？', '分條後的麵條要怎麼處理？', '麵條分條後的下一步？', '乾燥一共要多久的時間？', '為什麼需要去模擬日曬？', '請問乾燥室的工作原理？', '要怎麼確保麵條乾燥完成？', '為什麼要去模擬日曬？', '要怎麼模擬日曬來乾燥麵條？', '要怎麼判斷麵條乾燥完成？', '乾燥麵條有檢測什麼數據？', '麵條乾燥完成後下一步是什麼？', '裁切後的麵條如何分成一份？', '一份要分成100公克有什麼特殊原因嗎？', '麵條綑成一束下一步是什麼？', '什麼時候要用封口機封口後包裝？', '綑成一束的麵條要怎麼進行包裝？', '自動計量機用來做什麼？', '為什麼要用自動計量機？', '自動計量機要怎麼確保準確度？', '有哪些包裝的規格？', '請問封口包裝後下一步是什麼？', '製麵工廠如何確保產品的安全性？', '金屬檢測器的功能是什麼？', '為什麼需要用金屬檢測器？', '請問製麵的最終步驟是什麼？', '請問成品麵條的最終包裝過程是什麼？', '請問你們的包裝流程是什麼？', '請問你們如何進行成品的最終包裝？', '要怎麼確保麵條在包裝後不會受到污染？', '製麵工廠是怎麼防止成品在包裝後被污染？', '製麵工廠是怎麼防止異物進入包裝？', '請問清潔區是甚麼？', '請問包裝在哪個區？', '請問製麵工廠在什麼環境下包裝？', '請問準清潔區是甚麼？', '請問生產製麵在哪一區？', '請問鹽水間在哪一個區？', '請問製麵機在哪一個區？', '請問乾燥室在哪一個區？', '請問分切麵條在哪一個區？', '請問麵餅分條在哪一個區？', '清潔區有哪些特殊要求？', '工作人員需要穿什麼？', '這邊一共有8種商品，有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '請問這邊有多少商品？', '請問有幾種麵條？', '請問這邊商品有什麼？', '請問這邊麵條有什麼口味？', '請問有什麼麵條？', '請問有什麼口味的麵條？', '請問大呷麵本家要怎麼製作芋頭麵條？', '請問大呷麵本家要怎麼製作烏龍茶麵條？', '請問大呷麵本家要怎麼製作黑芝麻麵條？', '請問大呷麵本家要怎麼製作金盞花麵條？', '大呷麵本家的原料來自於哪裡？', '大呷麵本家的原料來自於台灣嗎？', '請問這邊商品價格多少？', '請問這邊麵條價格多少？', '請問原味的麵條價格多少？', '請問原味的麵線價格多少？', '請問黑芝麻麵條價格多少？', '請問芋頭麵條價格多少？', '請問糙米麵條價格多少？', '請問烏龍茶麵條價格多少？', '請問金盞花麵條價格多少？', '請問綠茶麵條價格多少？', '幫我介紹原味麵條', '幫我介紹原味麵線', '幫我介紹芋頭麵條', '幫我介紹糙米麵條', '幫我介紹烏龍茶麵條', '幫我介紹黑芝麻麵條', '幫我介紹金盞花麵條', '幫我介紹綠茶麵條']\n",
      "type2_B model values: ['我是大呷麵本家的製麵工廠虛擬導覽員', '位於台中市大甲的製作麵條工廠，且有精販賣精美的麵條禮盒', '這裡是大呷麵本家', '43750台中市大甲區重義二路153號', '04-2686-1026', 'noodlesorigin@gmail.com', '不是，我們是「大呷麵本家」', '在日本時代都稱為本家大甲。而又因地名不能申請商標，所以在大甲的甲字多個口部，加上麵字，就成為台灣人的用語，呷麵。這是一個結合日本時代的發跡跟台灣文化的融合。', 'Noodles Origin', '我們的產品通過ISO22000&HACCP國際食品安全管制系統認證。', '我們大呷麵本家麵條是基於台灣古早味改良，現在是用機械化產線製麵。', '大呷麵本家使用機械化產線製麵可以保持高水準的品質與食品安全，讓顧客有最好的飲食體驗。', '我們的鹽水間是用來調製鹽水，鹽水的濃度會依照標準化程序調製。', '我們會將調製好的鹽水再與麵粉按比例混合成為麵糰。', '每次製麵使用4包麵粉。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '我們的攪拌時間是ISO標準化的，根據標準進行正轉和負轉來壓製。', '製麵機會將麵糰分開桿成麵皮，再將兩部分疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分。', '製麵機會將麵糰分開桿成麵皮，再將兩部分疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分。', '透過滾輪輾壓來減少麵皮厚度，確保麵條達到標準厚度，不會變得過厚。', '透過在一開始就用兩片麵皮經過滾輪輾壓，確保麵條達到標準厚度，不會變得過薄。', '我們會將壓製成1公分的麵餅用麵刀依照規格分條，一共有四種規格：麵線、麵條、寬麵、最寬的麵。', '我們會將壓製成1公分的麵餅用麵刀依照規格分條，一共有四種規格：麵線、麵條、寬麵、最寬的麵。', '一共有四種規格：麵線、麵條、寬麵、最寬的麵。', '分條過程中使用麵刀，將壓製成1公分的麵餅用麵刀依照規格分條。', '分條後的麵條會掛在乾燥架上，送至乾燥室進行乾燥，乾燥室是模擬傳統日曬環境，通常會經過5個半小時的時間進行乾燥。', '分條後的麵條會掛在乾燥架上，送至乾燥室進行乾燥，乾燥室是模擬傳統日曬環境，通常會經過5個半小時的時間進行乾燥。', '麵條需要在乾燥室中乾燥5個半小時，模擬日曬的時間。', '因為我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '因為我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '切分完的麵條會在乾燥室乾燥，使麵條水分降低至12%，麵條水分必須降低至12%代表乾燥完成。', '切分完的麵條會在乾燥室乾燥，使麵條水分降低至12%，麵條水分必須降低至12%代表乾燥完成。', '乾燥完成的麵條依照長度進行切分，長度為19到20公分，並且將切分好的麵條捆成1束，通常1束為100公克。', '將切分好的麵條捆成1束，通常1束為100公克。', '因為100公克是一般人一餐所需的量。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，確保每一束麵條的份量一致。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，確保每一束麵條的份量一致。', '自動計量機定期進行校準，並通過電子感應系統精確測量每束麵條的重量，確保準確度。', '包裝有量販包裝、禮盒包裝。', '完成封口包裝後會經過金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '完成封口包裝後會經過金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '金屬檢測器用來檢查成品中是否有任何金屬雜質，確保食品衛生以及食品安全。', '金屬檢測器用來檢測麵條中是否含有金屬雜質，確保產品的安全和合格。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '在清潔區包裝後，成品經過封口機封口，並確保不會有交叉污染。', '在清潔區包裝後，成品經過封口機封口，並確保不會有交叉污染。', '工廠內採取清潔區和準清潔區分區的方式，並通過防護設備確保沒有交叉污染。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '準清潔區則是生產製麵的空間，例如鹽水間和乾燥室。', '準清潔區則是生產製麵的空間，例如鹽水間和乾燥室。', '準清潔區。', '準清潔區。', '準清潔區。', '準清潔區。', '準清潔區。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，並進行標準化防護操作，以確保食品衛生以及食品安全。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，並進行標準化防護操作，以確保食品衛生以及食品安全。', '好的。', '8種，其中有各式各樣口味的麵條與麵線', '8種，其中有各式各樣口味的麵條與麵線', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，金盞花麵條，綠茶麵條', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，麵條，綠茶麵條', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，金盞花麵條，綠茶麵條', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，金盞花麵條，綠茶麵條', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入大甲芋頭原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入烏龍茶原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入黑芝麻原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入金盞花原料進行混合。', '大呷麵本家的麵條原料來自於台灣當地的優質農產品。', '是的，大呷麵本家的麵條原料來自於台灣當地的優質農產品。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條是95元。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條是95元。', '原味的麵條90元。', '原味的麵線90元。', '黑芝麻麵條95元。', '芋頭麵條95元。', '糙米麵條95元。', '烏龍茶麵條95元。', '金盞花麵條95元。', '綠茶麵條95元。', '代代傳承、麵本家獨家的經典風味，來自於中部清澈的水質！唯有製麵達人八十年的真功夫，才能將麥穗鮮度完整保留在麵條中，讓您不只吃好味、更吃出新鮮！', '代代傳承、麵本家獨家的經典風味，來自於中部清澈的水質！唯有製麵達人八十年的真功夫，才能將麥穗鮮度完整保留在麵線中，讓您不只吃好味、更吃出新鮮！', '芋頭麵採用大甲芋，其肉質較為細膩黏滑粉質高(澱粉含量高)，肉色顯白，檳榔纖維絲也較細且淡，為大甲區特有產業，栽種面積有4百公頃，不但居全台之冠，其芋頭鬆軟，香Q品質也居全台之首。', '糙米麵條採用嘉義水上鄉之精心栽種糙米，在優質水質的澆灌下，孕育出絕佳的糙米風味。', '烏龍茶麵條採用原礦家有機烏龍茶葉研磨成粉，再經由製麵達人將高級的烏龍茶完美融入於本家麵條之中，讓麵條中保有烏龍茶原有之青香，讓您吃的健康，更使麵條口感加倍的清爽與彈牙。', '大呷麵本家採用最新低溫烘培技術的全顆黑芝麻，創造出完整保留芝麻原色營養以及香氣的黑芝麻麵，加上麵本家的製麵工夫運用高級麵粉、食鹽等原料製成，營養豐富，風味絕佳，讓您吃的無負擔 ，更使麵條口感加倍的清爽與彈牙！誠為家庭必備與饋贈親友之最佳禮品！', '金盞花不但色澤亮麗，其附帶的營養價值也極高，自古以來即被當作藥用植物，大呷麵本家特選優質金盞花做成的金盞花麵，給您視覺、味覺、無負擔的三重享受。', '嚴選梨山綠茶！由於晝夜溫差大的氣候條件，生產出品質較高的茶葉。製麵達人將高級的綠茶完美融入於本家麵條之中，讓您吃的無負擔，更使麵條口感加倍的清爽與彈牙！']\n",
      "type2_B length: 100\n",
      "\n",
      "type3_B user values: ['請問你是什麼人？', '請幫我安排去大呷麵本家的行程。', '請問大呷麵本家是什麼？', '請問這裡是什麼地方？', '請問大呷麵本家在哪裡？', '請問大呷麵本家的電話是多少？', '要如何聯絡到大呷麵本家？', '請問大呷麵本家的電子郵件？', '請問你們是叫大甲面本家嗎？', '大呷麵本家中的大呷是什麼意思？', '為什麼不要叫大甲麵本家？', '請問大呷麵本家的英文名字是什麼？', 'What is your english name?', '請問大呷麵本家什麼時候營業？', '請給我大呷麵本家的官網？', '請問大呷麵本家有什麼國際認證？', '請問大呷麵本家有用哪些原料來製麵？', '請問大呷麵本家製麵是怎麼製麵的？', '請問製麵工廠是怎麼實現生產機械化的？', '請問鹽水間是拿來做什麼的房間？', '請問在什麼時候要調製鹽水？', '那調製完鹽水的下一步？', '請問什麼時候要調製麵糰？', '那麵糰混合完成的下一步是什麼？', '請問製作特殊口味的麵條時，什麼時候要加入調味的原料？', '攪拌麵團的時間是如何控制的？', '在麵糰混和好口味的下一步是什麼？', '要怎麼保證麵條的厚度一致？', '請問要怎麼避免麵條變得太厚？', '請問要怎麼避免麵條變得太薄？', '在麵餅壓製好之後下一步是什麼？', '什麼時候可以進行分條？', '一共有哪些寬度的麵條？', '分條要用什麼工具？', '請問製麵流程中要怎麼處理不同寬度的麵條？', '請問完成分條後的長麵條下一步是什麼？', '請問長麵條要怎麼乾燥？', '請問你們長麵條的乾燥過程需要多久？', '請問乾燥時間要怎麼知道？', '為什麼要乾燥室模擬日曬？', '乾燥室的工作原理是什麼？', '要怎麼模擬日曬來乾燥長麵條？', '請問乾燥長麵條要檢測哪些數據？', '請問製麵過程中要怎麼確保長麵條的水分含量有達到標準？', '如果長麵條的水分含量超標會有什麼問題？', '那長麵條乾燥完成後的下一步是什麼？', '要在什麼時候進行切分？', '乾燥完成的長麵條是怎麼分成一份？', '長麵條乾燥完成後會切分成多長的麵條？', '請問半成品裁切完成後下一步是什麼？', '請問為什麼一份是分成100公克？', '請問將半成品切分完成後麵條綑成一束的下一步是什麼？', '什麼時候可以用封口機封口然後包裝？', '請問自動計量機的作用？', '請問製麵過程中為什麼要用自動計量機？', '請問自動計量機是什麼機器？', '請問大呷麵本家的包裝規格有哪些？', '在包裝完成封口後下一步是什麼？', '什麼時候可以進行金屬檢測？', '製麵工廠要怎麼確保產品的安全性？', '為什麼大呷麵本家需要使用金屬檢測器？', '請告訴我大呷麵本家的包裝流程是什麼？', '製麵工廠什麼時候可以進行成品的最終包裝？', '要怎麼確保麵條在包裝後不會受到污染？', '大呷麵本家如何防止蟲害問題？', '大呷麵本家如何防止成品在包裝後被污染？', '大呷麵本家如何防止異物進入包裝？', '請問清潔區是甚麼？', '請問在哪個區包裝？', '大呷麵本家是在什麼環境下包裝？', '請問準清潔區是甚麼？', '請問生產製麵是在哪一區？', '請問鹽水間哪一區？', '請問製麵機是在哪一區？', '請問乾燥室是在哪一區？', '請問分切長麵條是在哪一區？', '請問麵餅分條是在哪一區？', '大呷麵本家製麵的防護裝備有哪些？', '清潔區有什麼特殊要求？', '清潔區有哪些防護措施？', '請問在這裡一共有多少商品？', '請問有幾種麵條？', '請問這邊商品有哪些？', '這邊的麵條有什麼口味？', '請問有哪些麵條？', '請問有什哪些口味的麵條？', '大呷麵本家如何製作芋頭口味？', '大呷麵本家如何製作烏龍茶口味？', '請問你們的原料來自哪裡？', '請問你們的原料來自台灣嗎？', '請告訴我各種商品價格多少？', '請告訴我各種麵條價格多少？', '請問原味的麵條價格多少？', '請問原味的麵線價格多少？', '請問黑芝麻麵條價格多少？', '請問芋頭麵條價格多少？', '請問糙米麵條價格多少？', '請問烏龍茶麵條價格多少？', '請問金盞花麵條價格多少？', '請問綠茶麵條價格多少？']\n",
      "type3_B model values: ['我是大呷麵本家的製麵工廠虛擬導覽員。', '非常不好意思，安排行程不是我的專長，你可以問1F的導覽員。', '位於台中市大甲的製作麵條工廠，且有精販賣精美的麵條禮盒。', '這裡是大呷麵本家。', '大呷麵本家的地址是43750台中市大甲區重義二路153號。', '大呷麵本家的電話是04-2686-1026。', '可以用電話聯絡或者是電子郵件聯絡，我們的電話是04-2686-1026，我們的電子郵件是noodlesorigin@gmail.com。', '大呷麵本家的電子郵件是noodlesorigin@gmail.com。', '不是，我們是「大呷麵本家」。', '大呷源自於地名大甲，所以大甲的甲字口部加上家字成為台灣人的用語呷麵，這是結合日本時代的發跡和台灣文化的融合。', '在日本時代都稱為本家大甲。而又因地名不能申請商標，所以在大甲的甲字多個口部，加上麵字，就成為台灣人的用語，呷麵。這是一個結合日本時代的發跡跟台灣文化的融合。', '大呷麵本家的英文名字是Noodles Origin。', 'My name is Noodles Origin。', '大呷麵本家的營業時間是\"週一至週五/9:00~18:00（公司／故事館）；週六、週日/接受團體預約參觀（故事館）\"。', '大呷麵本家的官網是https://www.noodlesorigin.com/index.php?lang=tw。', '我們的產品通過ISO22000&HACCP國際食品安全管制系統認證。', '麵粉、鹽巴和水。', '大呷麵本家麵條是基於台灣古早味改良，現在是用機械化產線製麵。', '製麵工廠將自動攪拌、輾壓、分條、乾燥和計量設備設定標準，實現了大部分生產過程的機械化，以保持高水準的品質與食品安全。', '我們的鹽水間是用來調製鹽水，鹽水的濃度會依照標準化程序調製。', '製麵流程一開始在鹽水間是用來調製鹽水，鹽水的濃度會依照標準化程序調製。', '我們會將調製好的鹽水再與麵粉按比例混合成為麵糰。', '在鹽水調製好後，我們會將調製好的鹽水再與麵粉按比例混合成為麵糰。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '在麵糰混和好以後倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '攪拌麵團的時間是ISO標準化的，根據標準進行正轉和負轉來壓製。', '製麵機會將麵糰分開桿成麵皮，再將兩部分疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分。', '經由將分開成兩部分的麵皮疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分，確保不會有太薄或太厚的部分。', '透過滾輪輾壓來減少麵皮厚度，確保麵條達到標準厚度，不會變得過厚。', '透過在一開始就用兩片麵皮經過滾輪輾壓，確保麵條達到標準厚度，不會變得過薄。', '我們會將壓製成1公分的麵餅用麵刀依照寬度分條，一共有四種寬度：麵線、麵條、寬麵、最寬的麵。', '在將麵餅壓製成1公分後用麵刀依照寬度分條。', '一共有四種寬度：麵線、麵條、寬麵、最寬的麵。', '分條過程中使用麵刀。', '分條過程中使用麵刀，將壓製成1公分的麵餅用麵刀依照寬度分條。', '分條後的麵條會掛在乾燥架上，送至乾燥室進行乾燥。', '長麵條會掛在乾燥架上，送至乾燥室進行乾燥。', '視當天天氣情況而定，長麵條通常需要在乾燥室中乾燥5個半小時，模擬日曬的時間。', '視當天天氣情況而定，長麵條通常需要在乾燥室中乾燥5個半小時，如果乾燥程度不夠則會繼續乾燥。', '因為我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們控制溫度以及濕度模擬日曬的環境。', '我們經由控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '長麵條的乾燥程度，長麵條水分必須降低至12%。', '長麵條會在乾燥室乾燥使長麵條水分降低至12%，如果乾燥程度不夠則會繼續乾燥。', '如果長麵條的水分含量超過12%，它可能會在包裝後發霉或變質，影響品質。', '乾燥完成的長麵條依照長度進行切分，長度為19到20公分，並且將切分好的半成品麵條捆成1束，通常1束為100公克。', '在乾燥完成的長麵條依照長度進行切分，長度為19到20公分，。', '在依照19到20公分的長度切分好後的麵條捆成1束，通常1束為100公克。', '半成品麵條長度為19到20公分。', '將切分好的半成品麵條捆成1束，通常1束為100公克。', '因為100公克是一般人一餐所需的量。', '綑成一束的半成品麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '在半成品麵條綑綁完成後，經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '半成品麵條經過自動計量機檢測重量是否有達到標準，確保每一束半成品麵條的份量一致。', '要使用自動計量機檢測半成品麵條重量是否有達到標準，確保每一束半成品麵條的份量一致。', '自動計量機檢測半成品麵條重量是否有達到標準，確保每一束半成品麵條的份量一致。', '包裝有量販包裝、禮盒包裝。', '完成封口包裝後會經過金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '在半成品麵條完成封口包裝後會經過金屬檢測機和含水量檢查。', '使用金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '因為金屬檢測器可以用來檢測麵條中是否含有金屬雜質，確保食品的安全。', '成品經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '在經過封口、金屬檢測和含水量檢查後包裝，有量販包裝、禮盒包裝。。', '我們藉由清潔區分區，成品經過封口機封口後不再接觸外界環境，確保不會有交叉污染。', '我們藉由清潔區分區，成品經過封口機封口後不再接觸外界環境，以防止蟲害問題。', '我們藉由清潔區分區，成品經過封口機封口後不再接觸外界環境，以防止成品遭受汙染。', '工廠內採取清潔區和準清潔區分區的方式，並通過防護設備確保沒有交叉污染。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '包裝在清潔區。', '我們在清潔區包裝。', '準清潔區則是生產製麵的空間，例如鹽水間和乾燥室。', '生產製麵在準清潔區。', '鹽水間在準清潔區。', '製麵機在準清潔區。', '乾燥室在準清潔區。', '分切長麵條在準清潔區。', '麵餅分條在準清潔區。', '工作人員防護裝備有防塵衣、口罩、髮網、鞋套等防護裝備。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，並進行標準化防護操作，以確保食品衛生以及食品安全。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，進場前有風淋室。', '8種，其中有各式各樣口味的麵條與麵線', '8種，其中有各式各樣口味的麵條與麵線', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '我們會將鹽水與麵粉混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入大甲芋頭原料進行混合。', '我們會將鹽水與麵粉混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入烏龍茶原料進行混合。', '我們的麵條原料來自於台灣當地的優質農產品。', '是的，我們的麵條原料來自於台灣當地的優質農產品。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條都是95元。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條都是95元。', '原味的麵條是90元。', '原味的麵線是90元。', '黑芝麻麵條是95元。', '芋頭麵條是95元。', '糙米麵條是95元。', '烏龍茶麵條是95元。', '金盞花麵條是95元。', '綠茶麵條是95元。']\n",
      "type3_B length: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:\\\\Serious\\\\Program\\\\Github\\\\noodle_LLM\")\n",
    "\n",
    "dir_test_dataset = \"./training/LLM_eval/testDataset/\"\n",
    "dir_chat_output= \"./training/LLM_eval/chatOutput/\"\n",
    "dir_output = \"./training/LLM_eval/evalOutput/\"\n",
    "\n",
    "# \n",
    "model_candidate = {}\n",
    "for i in model_list:\n",
    "    model_candidate[i] = f\"{dir_chat_output}{i}.csv\"\n",
    "\n",
    "#\n",
    "user_values = {}\n",
    "model_values = {}\n",
    "chat_len = {}\n",
    "\n",
    "for i in type_list:\n",
    "    with open(f\"{dir_test_dataset}{i}.csv\", mode='r', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        # init\n",
    "        user_values[i] = []\n",
    "        model_values[i] = []\n",
    "        chat_len[i] = 0\n",
    "\n",
    "        for row in csv_reader:\n",
    "            user_values[i].append(row['user'])\n",
    "            model_values[i].append(row['model'])\n",
    "    if len(user_values[i]) == len(user_values[i]):\n",
    "        chat_len[i] = len(user_values[i])\n",
    "\n",
    "for i in type_list:\n",
    "    print(f\"{i} user values: {user_values[i]}\")\n",
    "    print(f\"{i} model values: {model_values[i]}\")\n",
    "    print(f\"{i} length: {chat_len[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 測試評估資料集是否有讀取到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': '幫我介紹綠茶麵條'}\n",
      "{'role': 'user', 'content': '請問綠茶麵條價格多少？'}\n"
     ]
    }
   ],
   "source": [
    "for i in type_list:    \n",
    "    messages={\"role\": \"user\", \"content\": user_values[i][chat_len[i]-1]}\n",
    "    print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 匯入模型問答csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type3-256-300E32B_B: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-300E64B_B: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-300E128B_B: 大呷麵本家的電話是04-2686-1026。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_answer={}\n",
    "latency_t = {}\n",
    "\n",
    "# 動態創建變數並存儲 Model's Answer\n",
    "for key, file_path in model_candidate.items():\n",
    "    df = pd.read_csv(f'{file_path}')\n",
    "\n",
    "    # 提取 \"Model's Answer\" 列並轉換為列表\n",
    "    real_answer[key] = df[\"Model's Answer\"].tolist()\n",
    "    latency_t[key] = df[\"Latency\"].tolist()\n",
    "\n",
    "# 確認變數是否正確創建和存儲\n",
    "for i in real_answer:\n",
    "    print(f\"{i}: {real_answer[i][5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 評估 ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Sean\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.530 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type3-256-300E32B_B Average Scores:\n",
      "rouge-1: {'r': 0.7575, 'p': 0.691, 'f': 0.7243}\n",
      "rouge-2: {'r': 0.6145, 'p': 0.5625, 'f': 0.5885}\n",
      "rouge-l: {'r': 0.7239, 'p': 0.6504, 'f': 0.6872}\n",
      "\n",
      "Average f1-score: 0.6667\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-300E64B_B Average Scores:\n",
      "rouge-1: {'r': 0.7292, 'p': 0.4991, 'f': 0.6141}\n",
      "rouge-2: {'r': 0.5299, 'p': 0.3516, 'f': 0.4407}\n",
      "rouge-l: {'r': 0.6826, 'p': 0.4155, 'f': 0.549}\n",
      "\n",
      "Average f1-score: 0.5346\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-300E128B_B Average Scores:\n",
      "rouge-1: {'r': 0.7513, 'p': 0.6683, 'f': 0.7098}\n",
      "rouge-2: {'r': 0.5925, 'p': 0.5185, 'f': 0.5555}\n",
      "rouge-l: {'r': 0.7094, 'p': 0.6108, 'f': 0.6601}\n",
      "\n",
      "Average f1-score: 0.6418\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cc = OpenCC('t2s')\n",
    "rouge = Rouge()\n",
    "def evaluate_ROUGE(model_values, model_ans, model_name, scores_list, count):\n",
    "    \n",
    "    for i in range(count):\n",
    "        completion = model_ans[i]\n",
    "        reference = model_values[i]\n",
    "\n",
    "        reference = cc.convert(reference)\n",
    "        reference = '/ '.join(jieba.cut(reference, cut_all=False))\n",
    "        \n",
    "        generated_answer = completion\n",
    "        generated_answer = cc.convert(generated_answer)\n",
    "        generated_answer = '/ '.join(jieba.cut(generated_answer, cut_all=False))\n",
    "        \n",
    "        score = rouge.get_scores(generated_answer, reference)\n",
    "        scores_list.append(score)\n",
    "        \n",
    "    avg_scores = {'rouge-1': {'r': 0, 'p': 0, 'f': 0},\n",
    "        'rouge-2': {'r': 0, 'p': 0, 'f': 0},\n",
    "        'rouge-l': {'r': 0, 'p': 0, 'f': 0}}\n",
    "\n",
    "    num_instances = len(scores_list)\n",
    "    for instance_scores in scores_list:\n",
    "        for metric, metrics_scores in instance_scores[0].items():\n",
    "            for score_type, value in metrics_scores.items():\n",
    "                if score_type != 'f':  # 暫時跳過 'f' 分數\n",
    "                    avg_scores[metric][score_type] += value / num_instances\n",
    "\n",
    "    # 根據 (r + p) / 2 來計算新的 'f' 分數，並四捨五入到小數點第四位\n",
    "    for metric, metrics_scores in avg_scores.items():\n",
    "        r = metrics_scores['r']\n",
    "        p = metrics_scores['p']\n",
    "        avg_scores[metric]['f'] = round((r + p) / 2, 4)\n",
    "        avg_scores[metric]['r'] = round(r, 4)\n",
    "        avg_scores[metric]['p'] = round(p, 4)\n",
    "\n",
    "    # 計算 rouge-1, rouge-2, rouge-l 的 f 分數平均值\n",
    "    f_score_avg = (avg_scores['rouge-1']['f'] + avg_scores['rouge-2']['f'] + avg_scores['rouge-l']['f']) / 3\n",
    "    f_score_avg = round(f_score_avg, 4)\n",
    "    tmp = []\n",
    "\n",
    "    print(model_name,\"Average Scores:\")\n",
    "    for metric, metrics_scores in avg_scores.items():\n",
    "        print(f\"{metric}: {metrics_scores}\")\n",
    "        tmp.append(metrics_scores['f'])\n",
    "    print(f\"\\nAverage f1-score: {f_score_avg}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "\n",
    "   \n",
    "    ori_data[model_name] = (tmp[0], tmp[1], tmp[2], f_score_avg)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "scores_dict = {}\n",
    "for i in real_answer:\n",
    "    scores_dict[i] = []\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}ROUGE_B.csv'):\n",
    "    with open(f'{dir_output}ROUGE_B.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = (row[\"rouge-1\"],row[\"rouge-2\"],row[\"rouge-l\"],row[\"Average\"])\n",
    "\n",
    "with open(f'{dir_output}ROUGE_B.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"rouge-1\", \"rouge-2\",\"rouge-l\",\"Average\"]) \n",
    "    for i in real_answer:\n",
    "        if \"type2\" in i:\n",
    "            std_answer = model_values[\"type2_B\"]\n",
    "            c_len = chat_len[\"type2_B\"]\n",
    "        elif \"type3\" in i:\n",
    "            std_answer = model_values[\"type3_B\"]\n",
    "            c_len = chat_len[\"type3_B\"]\n",
    "        evaluate_ROUGE(std_answer, real_answer[i], i, scores_dict[i], c_len)\n",
    "\n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i][0], ori_data[i][1], ori_data[i][2], ori_data[i][3]])\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 評估 Sentence-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type3-256-300E32B_B SentenceTransformer Semantic Similarity score: 0.7734\n",
      "lora_type3-256-300E64B_B SentenceTransformer Semantic Similarity score: 0.6622\n",
      "lora_type3-256-300E128B_B SentenceTransformer Semantic Similarity score: 0.7691\n"
     ]
    }
   ],
   "source": [
    "ST_model = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
    "\n",
    "\n",
    "def evaluate_ST(model_values, model_ans, model_name, scores_dict, count):\n",
    "    for i in range(0, count):\n",
    "        completion = model_ans[i]\n",
    "        reference = model_values[i]\n",
    "        generated_answer = completion\n",
    "        \n",
    "        e_q = ST_model.encode(generated_answer)        \n",
    "        embeddings = ST_model.encode(reference)       \n",
    "        sym = float(util.pytorch_cos_sim(e_q, embeddings).detach().numpy()[0][0])\n",
    "        score = sym\n",
    "        scores_dict.append(score)\n",
    "        \n",
    "    avg_scores = round(sum(scores_dict)/len(scores_dict), 4)\n",
    "    print(model_name,\"SentenceTransformer Semantic Similarity score:\", avg_scores)\n",
    "\n",
    "    ori_data[model_name] = avg_scores\n",
    "\n",
    "\n",
    "scores_dict = {}\n",
    "for i in real_answer:\n",
    "    scores_dict[i] = []\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}ST_B.csv'):\n",
    "    with open(f'{dir_output}ST_B.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = (row[\"ST\"])\n",
    "\n",
    "with open(f'{dir_output}ST_B.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"ST\"]) \n",
    "    for i in real_answer:\n",
    "        if \"type2\" in i:\n",
    "            std_answer = model_values[\"type2_B\"]\n",
    "            c_len = chat_len[\"type2_B\"]\n",
    "        elif \"type3\" in i:\n",
    "            std_answer = model_values[\"type3_B\"]\n",
    "            c_len = chat_len[\"type3_B\"]\n",
    "        evaluate_ST(std_answer, real_answer[i], i, scores_dict[i], c_len)\n",
    "\n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 評估 BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type3-256-300E32B_B BLEU-1 score: 0.6879\n",
      "lora_type3-256-300E32B_B BLEU-2 score: 0.6261\n",
      "lora_type3-256-300E32B_B BLEU-3 score: 0.5822\n",
      "lora_type3-256-300E32B_B BLEU-4 score: 0.5482\n",
      "lora_type3-256-300E32B_B BLEU score: 0.6003\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Serious\\Program\\venvs\\noodle_LLM\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Serious\\Program\\venvs\\noodle_LLM\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type3-256-300E64B_B BLEU-1 score: 0.457\n",
      "lora_type3-256-300E64B_B BLEU-2 score: 0.4019\n",
      "lora_type3-256-300E64B_B BLEU-3 score: 0.36\n",
      "lora_type3-256-300E64B_B BLEU-4 score: 0.3291\n",
      "lora_type3-256-300E64B_B BLEU score: 0.3747\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-300E128B_B BLEU-1 score: 0.6517\n",
      "lora_type3-256-300E128B_B BLEU-2 score: 0.5777\n",
      "lora_type3-256-300E128B_B BLEU-3 score: 0.5301\n",
      "lora_type3-256-300E128B_B BLEU-4 score: 0.4932\n",
      "lora_type3-256-300E128B_B BLEU score: 0.5502\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_BLEU(model_values, model_ans, model_name, scores_dict, count):\n",
    "\n",
    "    \n",
    "    candidate_list = list()\n",
    "    reference_list = list()\n",
    "    \n",
    "    bleu_1_scores = []\n",
    "    bleu_2_scores = []\n",
    "    bleu_3_scores = []\n",
    "    bleu_4_scores = []\n",
    "    bleu_avg_scores = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, count):\n",
    "        completion = model_ans[i]\n",
    "        reference = model_values[i]     \n",
    "        \n",
    "        # 將生成的句子逐字切分\n",
    "        generated_answer_sepWords = ' '.join(jieba.cut(completion))\n",
    "        generated_answer = list(generated_answer_sepWords)\n",
    "        candidate_list.append(generated_answer)\n",
    "    \n",
    "        # 將參考句子逐字切分\n",
    "        reference_sepWords = ' '.join(jieba.cut(reference))\n",
    "        reference_answer = list(reference_sepWords)\n",
    "        reference_list.append([reference_answer])\n",
    "\n",
    "        bleu_1_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(0, 1, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(0, 0, 1, 0))\n",
    "        bleu_4_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(0, 0, 0, 1))\n",
    "        bleu_avg_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i])\n",
    "        \n",
    "        bleu_1_scores.append(bleu_1_score)\n",
    "        bleu_2_scores.append(bleu_2_score)\n",
    "        bleu_3_scores.append(bleu_3_score)\n",
    "        bleu_4_scores.append(bleu_4_score)\n",
    "        bleu_avg_scores.append(bleu_avg_score)\n",
    "        \n",
    "    avg_bleu_1 = round(sum(bleu_1_scores) / len(bleu_1_scores), 4)\n",
    "    avg_bleu_2 = round(sum(bleu_2_scores) / len(bleu_2_scores), 4)\n",
    "    avg_bleu_3 = round(sum(bleu_3_scores) / len(bleu_3_scores), 4)\n",
    "    avg_bleu_4 = round(sum(bleu_4_scores) / len(bleu_4_scores), 4)\n",
    "    avg_bleu_avg = round(sum(bleu_avg_scores) / len(bleu_avg_scores), 4)\n",
    "    print(f\"{model_name} BLEU-1 score: {avg_bleu_1}\")\n",
    "    print(f\"{model_name} BLEU-2 score: {avg_bleu_2}\")\n",
    "    print(f\"{model_name} BLEU-3 score: {avg_bleu_3}\")\n",
    "    print(f\"{model_name} BLEU-4 score: {avg_bleu_4}\")\n",
    "    print(f\"{model_name} BLEU score: {avg_bleu_avg}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    ori_data[model_name] = avg_bleu_avg\n",
    "\n",
    "\n",
    "scores_dict = {}\n",
    "for i in real_answer:\n",
    "    scores_dict[i] = []\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}BLEU_B.csv'):\n",
    "    with open(f'{dir_output}BLEU_B.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = (row[\"BLEU\"])\n",
    "\n",
    "with open(f'{dir_output}BLEU_B.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"BLEU\"]) \n",
    "    for i in real_answer:\n",
    "        if \"type2\" in i:\n",
    "            std_answer = model_values[\"type2_B\"]\n",
    "            c_len = chat_len[\"type2_B\"]\n",
    "        elif \"type3\" in i:\n",
    "            std_answer = model_values[\"type3_B\"]\n",
    "            c_len = chat_len[\"type3_B\"]\n",
    "        evaluate_BLEU(std_answer, real_answer[i], i, scores_dict[i], c_len)\n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 評估延遲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type3-256-300E32B_B latency: 4.315 s\n",
      "lora_type3-256-300E64B_B latency: 6.83 s\n",
      "lora_type3-256-300E128B_B latency: 4.166 s\n"
     ]
    }
   ],
   "source": [
    "def evaluate_latency(model_name):\n",
    "    average = sum(latency_t[model_name]) / len(latency_t[model_name])\n",
    "    average = round(average, 3)\n",
    "    print(f\"{model_name} latency: {average} s\")\n",
    "\n",
    "    ori_data[model_name] = average\n",
    "\n",
    "\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}LATENCY_B.csv'):\n",
    "    with open(f'{dir_output}LATENCY_B.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = row[\"LATENCY\"]\n",
    "\n",
    "with open(f'{dir_output}LATENCY_B.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"LATENCY\"])\n",
    "    for i in model_list:\n",
    "        evaluate_latency(i)\n",
    "    \n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noodle_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
