{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "導入各個套件，切詞、ROUGE、BLEU、sentence transformers、csv...等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os\n",
    "import jieba\n",
    "from rouge_chinese import Rouge\n",
    "from opencc import OpenCC\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 參數選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"lora_type2-8-50E64B_A\",\n",
    "\"lora_type2-8-100E64B_A\",\n",
    "\"lora_type2-128-50E64B_A\",\n",
    "\"lora_type2-128-100E64B_A\",\n",
    "\"lora_type2-256-50E64B_A\",\n",
    "\"lora_type2-256-100E64B_A\",\n",
    "\"lora_type3-256-100E32B_A\",\n",
    "\"lora_type3-256-100E64B_A_old\",\n",
    "\"lora_type3-256-100E64B_2_A\",\n",
    "\"lora_type3-256-100E128B_A\",\n",
    "\"lora_type3-256-150E32B_A\",\n",
    "\"lora_type3-256-200E32B_A\",\n",
    "\"lora_type3-256-200E64B_A\",\n",
    "\"lora_type3-256-200E128B_A\",\n",
    "\"lora_type3-256-200E128B_2_A\",\n",
    "\"lora_type3-256-300E32B_A\",\n",
    "\"lora_type3-256-300E64B_A\",\n",
    "\"lora_type3-256-300E128B_A\",\n",
    "\n",
    "\n",
    "type_list = [\"type2_A\", \"type3_A\"]\n",
    "model_list = [\n",
    "\"lora_type2-8-50E64B_A\",\n",
    "\"lora_type2-128-50E64B_A\",\n",
    "\"lora_type2-128-100E64B_A\",\n",
    "\"lora_type2-256-50E64B_A\",\n",
    "\"lora_type2-256-100E64B_A\",\n",
    "\"lora_type3-256-100E32B_A\",\n",
    "\"lora_type3-256-100E64B_A_old\",\n",
    "\"lora_type3-256-100E64B_2_A\",\n",
    "\"lora_type3-256-100E128B_A\",\n",
    "\"lora_type3-256-150E32B_A\",\n",
    "\"lora_type3-256-200E32B_A\",\n",
    "\"lora_type3-256-200E64B_A\",\n",
    "\"lora_type3-256-200E128B_A\",\n",
    "\"lora_type3-256-200E128B_2_A\",\n",
    "\"lora_type3-256-300E32B_A\",\n",
    "\"lora_type3-256-300E64B_A\",\n",
    "\"lora_type3-256-300E128B_A\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type2_A user values: ['你是誰？', '大呷麵本家是什麼？', '這裡是哪裡？', '大呷麵本家的地址？', '大呷麵本家的電話？', '大呷麵本家的電子郵件？', '你們是大甲面本家嗎？', '為什麼不叫大甲麵本家？', '大呷麵本家的英文是什麼？', '大呷麵本家有哪些國際認證？', '大呷麵本家製麵是如何製麵的？', '使用機械化產線製麵有哪些好處？', '鹽水間是用來做什麼的？', '調製完鹽水下一步是什麼？', '每次製麵時使用多少麵粉？', '混合成為麵糰下一步是什麼？', '特殊口味的麵條如何製作？', '下料槽的功能是什麼？', '攪拌麵團的時間是怎麼控制的？', '製麵流程中如何控制麵餅厚度？', '製麵流程中如何避免麵條變得太厚？', '製麵流程中如何避免麵條變得太薄？', '壓製好的麵餅下一步是什麼？', '製麵流程如何將麵餅分條？', '有機種規格的麵條？', '分條使用的工具是什麼？', '分條後的麵條如何處理？', '分條後的麵條下一步是什麼？', '乾燥要多久？', '為什麼要模擬日曬？', '乾燥室的工作原理是什麼？', '如何確保麵條乾燥完成？', '為什麼要模擬日曬？', '如何模擬日曬來乾燥麵條？', '如何判斷麵條乾燥完成？', '乾燥麵條需要檢測什麼數據？', '乾燥完成的麵條下一步是什麼？', '裁切完成的麵條如何分成一份？', '為什麼一份要分成100公克？', '將切分完成的麵條綑成一束下一步是什麼？', '什麼時候進行封口機封口後包裝？', '綑成一束的麵條如何進行包裝？', '自動計量機有什麼作用？', '製麵過程中為什麼使用自動計量機？', '製麵工廠的自動計量機如何確保準確度？', '包裝的規格有哪些？', '封口包裝下一步是什麼？', '製麵工廠如何確保產品的安全性？', '金屬檢測器的作用是什麼？', '為什麼製麵需要使用金屬檢測器？', '製麵的最終步驟是什麼？', '成品麵條的最終包裝過程是什麼？', '製麵工廠的包裝流程是什麼？', '製麵工廠如何進行成品的最終包裝？', '如何確保麵條在包裝後不會受到污染？', '製麵工廠如何防止成品在包裝後被污染？', '製麵工廠如何防止異物進入包裝？', '什麼是清潔區？', '包裝在哪個區？', '大呷麵製麵工廠是在什麼環境下包裝？', '什麼是準清潔區？', '生產製麵是在哪一區？', '鹽水間哪一區？', '製麵機是在哪一區？', '乾燥室是在哪一區？', '分切麵條是在哪一區？', '麵餅分條是在哪一區？', '製麵工廠的清潔區有什麼特殊要求？', '製麵工廠內的工作人員需要穿什麼？', '這邊一共有8種商品，有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '這邊一共有多少商品？', '有幾種麵條？', '這邊商品有什麼？', '這邊麵條有什麼口味？', '有什麼麵條？', '有什麼口味的麵條？', '大呷麵本家如何製作芋頭麵條？', '大呷麵本家如何製作烏龍茶麵條？', '大呷麵本家如何製作黑芝麻麵條？', '大呷麵本家如何製作金盞花麵條？', '你們的原料來自於哪裡？', '你們的原料來自於台灣嗎？', '這邊商品價格多少？', '這邊麵條價格多少？', '這邊原味的麵條價格多少？', '這邊原味的麵線價格多少？', '這邊黑芝麻麵條價格多少？', '這邊芋頭麵條價格多少？', '這邊糙米麵條價格多少？', '這邊烏龍茶麵條價格多少？', '這邊金盞花麵條價格多少？', '這邊綠茶麵條價格多少？', '請介紹原味麵條', '請介紹原味麵線', '請介紹芋頭麵條', '請介紹糙米麵條', '請介紹烏龍茶麵條', '請介紹黑芝麻麵條', '請介紹金盞花麵條', '請介紹綠茶麵條']\n",
      "type2_A model values: ['我是大呷麵本家的製麵工廠虛擬導覽員', '位於台中市大甲的製作麵條工廠，且有精販賣精美的麵條禮盒', '這裡是大呷麵本家', '43750台中市大甲區重義二路153號', '04-2686-1026', 'noodlesorigin@gmail.com', '不是，我們是「大呷麵本家」', '在日本時代都稱為本家大甲。而又因地名不能申請商標，所以在大甲的甲字多個口部，加上麵字，就成為台灣人的用語，呷麵。這是一個結合日本時代的發跡跟台灣文化的融合。', 'Noodles Origin', '我們的產品通過ISO22000&HACCP國際食品安全管制系統認證。', '我們大呷麵本家麵條是基於台灣古早味改良，現在是用機械化產線製麵。', '大呷麵本家使用機械化產線製麵可以保持高水準的品質與食品安全，讓顧客有最好的飲食體驗。', '我們的鹽水間是用來調製鹽水，鹽水的濃度會依照標準化程序調製。', '我們會將調製好的鹽水再與麵粉按比例混合成為麵糰。', '每次製麵使用4包麵粉。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '我們的攪拌時間是ISO標準化的，根據標準進行正轉和負轉來壓製。你是一個有禮貌的大呷麵本家的製麵工廠虛擬導覽員', '製麵機會將麵糰分開桿成麵皮，再將兩部分疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分。', '透過滾輪輾壓來減少麵皮厚度，確保麵條達到標準厚度，不會變得過厚。', '透過在一開始就用兩片麵皮經過滾輪輾壓，確保麵條達到標準厚度，不會變得過薄。', '我們會將壓製成1公分的麵餅用麵刀依照規格分條，一共有四種規格：麵線、麵條、寬麵、最寬的麵。', '我們會將壓製成1公分的麵餅用麵刀依照規格分條，一共有四種規格：麵線、麵條、寬麵、最寬的麵。', '一共有四種規格：麵線、麵條、寬麵、最寬的麵。', '分條過程中使用麵刀，將壓製成1公分的麵餅用麵刀依照規格分條。', '分條後的麵條會掛在乾燥架上，送至乾燥室進行乾燥，乾燥室是模擬傳統日曬環境，通常會經過5個半小時的時間進行乾燥。', '分條後的麵條會掛在乾燥架上，送至乾燥室進行乾燥，乾燥室是模擬傳統日曬環境，通常會經過5個半小時的時間進行乾燥。', '麵條需要在乾燥室中乾燥5個半小時，模擬日曬的時間。', '因為我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '因為我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '切分完的麵條會在乾燥室乾燥，使麵條水分降低至12%，麵條水分必須降低至12%代表乾燥完成。', '切分完的麵條會在乾燥室乾燥，使麵條水分降低至12%，麵條水分必須降低至12%代表乾燥完成。', '乾燥完成的麵條依照長度進行切分，長度為19到20公分，並且將切分好的麵條捆成1束，通常1束為100公克。', '將切分好的麵條捆成1束，通常1束為100公克。', '因為100公克是一般人一餐所需的量。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，確保每一束麵條的份量一致。', '綑成一束的麵條經過自動計量機檢測重量是否有達到標準，確保每一束麵條的份量一致。', '自動計量機定期進行校準，並通過電子感應系統精確測量每束麵條的重量，確保準確度。', '包裝有量販包裝、禮盒包裝。', '完成封口包裝後會經過金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '完成封口包裝後會經過金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '金屬檢測器用來檢查成品中是否有任何金屬雜質，確保食品衛生以及食品安全。', '金屬檢測器用來檢測麵條中是否含有金屬雜質，確保產品的安全和合格。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '成品麵條經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '在清潔區包裝後，成品經過封口機封口，並確保不會有交叉污染。', '在清潔區包裝後，成品經過封口機封口，並確保不會有交叉污染。', '工廠內採取清潔區和準清潔區分區的方式，並通過防護設備確保沒有交叉污染。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '準清潔區則是生產製麵的空間，例如鹽水間和乾燥室。', '準清潔區則是生產製麵的空間，例如鹽水間和乾燥室。', '準清潔區。', '準清潔區。', '準清潔區。', '準清潔區。', '準清潔區。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，並進行標準化防護操作，以確保食品衛生以及食品安全。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，並進行標準化防護操作，以確保食品衛生以及食品安全。', '好的。', '8種，其中有各式各樣口味的麵條與麵線', '8種，其中有各式各樣口味的麵條與麵線', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，金盞花麵條，綠茶麵條', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，麵條，綠茶麵條', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，金盞花麵條，綠茶麵條', '有原味麵條，原味麵線，黑芝麻麵條，芋頭麵條，糙米麵條，烏龍茶麵條，金盞花麵條，綠茶麵條', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入大甲芋頭原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入烏龍茶原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入黑芝麻原料進行混合。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入金盞花原料進行混合。', '大呷麵本家的麵條原料來自於台灣當地的優質農產品。', '是的，大呷麵本家的麵條原料來自於台灣當地的優質農產品。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條是95元。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條是95元。', '原味的麵條90元。', '原味的麵線90元。', '黑芝麻麵條95元。', '芋頭麵條95元。', '糙米麵條95元。', '烏龍茶麵條95元。', '金盞花麵條95元。', '綠茶麵條95元。', '代代傳承、麵本家獨家的經典風味，來自於中部清澈的水質！唯有製麵達人八十年的真功夫，才能將麥穗鮮度完整保留在麵條中，讓您不只吃好味、更吃出新鮮！', '代代傳承、麵本家獨家的經典風味，來自於中部清澈的水質！唯有製麵達人八十年的真功夫，才能將麥穗鮮度完整保留在麵線中，讓您不只吃好味、更吃出新鮮！', '芋頭麵採用大甲芋，其肉質較為細膩黏滑粉質高(澱粉含量高)，肉色顯白，檳榔纖維絲也較細且淡，為大甲區特有產業，栽種面積有4百公頃，不但居全台之冠，其芋頭鬆軟，香Q品質也居全台之首。', '糙米麵條採用嘉義水上鄉之精心栽種糙米，在優質水質的澆灌下，孕育出絕佳的糙米風味。', '烏龍茶麵條採用原礦家有機烏龍茶葉研磨成粉，再經由製麵達人將高級的烏龍茶完美融入於本家麵條之中，讓麵條中保有烏龍茶原有之青香，讓您吃的健康，更使麵條口感加倍的清爽與彈牙。', '大呷麵本家採用最新低溫烘培技術的全顆黑芝麻，創造出完整保留芝麻原色營養以及香氣的黑芝麻麵，加上麵本家的製麵工夫運用高級麵粉、食鹽等原料製成，營養豐富，風味絕佳，讓您吃的無負擔 ，更使麵條口感加倍的清爽與彈牙！誠為家庭必備與饋贈親友之最佳禮品！', '金盞花不但色澤亮麗，其附帶的營養價值也極高，自古以來即被當作藥用植物，大呷麵本家特選優質金盞花做成的金盞花麵，給您視覺、味覺、無負擔的三重享受。', '嚴選梨山綠茶！由於晝夜溫差大的氣候條件，生產出品質較高的茶葉。製麵達人將高級的綠茶完美融入於本家麵條之中，讓您吃的無負擔，更使麵條口感加倍的清爽與彈牙！']\n",
      "type2_A length: 100\n",
      "\n",
      "type3_A user values: ['你是誰？', '請你幫我安排去大呷麵本家的旅遊行程。', '大呷麵本家是什麼？', '這裡是哪裡？', '大呷麵本家的地址？', '大呷麵本家的電話？', '如何聯絡大呷麵本家？', '大呷麵本家的電子郵件？', '你們是大甲面本家嗎？', '大呷麵本家的名稱中的大呷是什麼意思？', '為什麼不叫大甲麵本家？', '大呷麵本家的英文名字是什麼？', 'What is your english name?', '大呷麵本家的營業時間？', '大呷麵本家的官網？', '大呷麵本家有哪些國際認證？', '大呷麵本家用哪些原料製麵？', '大呷麵本家製麵是如何製麵的？', '製麵工廠是如何實現生產機械化的？', '鹽水間是用來做什麼的？', '什麼時候調製鹽水？', '調製完鹽水下一步是什麼？', '什麼時候調製麵糰？', '混合成為麵糰下一步是什麼？', '製作特殊口味的麵條時，什麼時候加入調味的原料？', '攪拌麵團的時間是怎麼控制的？', '混和好口味的麵糰下一步是什麼？', '如何保證麵條的厚度一致？', '製麵流程中如何避免麵條變得太厚？', '製麵流程中如何避免麵條變得太薄？', '壓製好的麵餅下一步是什麼？', '什麼時候進行分條？', '有幾種寬度的麵條？', '分條使用的工具是什麼？', '製麵流程中如何處理不同寬度的麵條？', '分條後的長麵條下一步是什麼？', '長麵條是如何乾燥？', '長麵條的乾燥過程需要多久？', '乾燥時間是如何確定的？', '為什麼要模擬日曬？', '乾燥室的工作原理是什麼？', '如何模擬日曬來乾燥長麵條？', '乾燥長麵條需要檢測什麼數據？', '製麵過程中如何確保長麵條的水分含量達標？', '長麵條的水分含量超標會有什麼問題？', '乾燥完成的長麵條下一步是什麼？', '什麼時候進行切分？', '乾燥完成的長麵條如何分成一份？', '乾燥完成的長麵條會切分成多長的麵條？', '裁切完成的半成品麵條下一步是什麼？', '為什麼一份要分成100公克？', '將切分完成的半成品麵條綑成一束下一步是什麼？', '什麼時候進行封口機封口後包裝？', '自動計量機有什麼作用？', '製麵過程中為什麼使用自動計量機？', '自動計量機是什麼？', '包裝的規格有哪些？', '封口包裝下一步是什麼？', '什麼時候進行金屬檢測？', '製麵工廠如何確保產品的安全性？', '為什麼製麵需要使用金屬檢測器？', '製麵工廠的包裝流程是什麼？', '製麵工廠如何進行成品的最終包裝？', '如何確保麵條在包裝後不會受到污染？', '製麵工廠如何防止蟲害問題？', '製麵工廠如何防止成品在包裝後被污染？', '製麵工廠如何防止異物進入包裝？', '什麼是清潔區？', '包裝在哪個區？', '大呷麵製麵工廠是在什麼環境下包裝？', '什麼是準清潔區？', '生產製麵是在哪一區？', '鹽水間哪一區？', '製麵機是在哪一區？', '乾燥室是在哪一區？', '分切長麵條是在哪一區？', '麵餅分條是在哪一區？', '製麵過程中的防護裝備有哪些？', '製麵工廠的清潔區有什麼特殊要求？', '製麵工廠的清潔區有哪些防護措施？', '這邊一共有多少商品？', '有幾種麵條？', '這邊商品有什麼？', '這邊麵條有什麼口味？', '有什麼麵條？', '有什麼口味的麵條？', '大呷麵本家如何製作芋頭口味？', '大呷麵本家如何製作烏龍茶口味？', '你們的原料來自於哪裡？', '你們的原料來自於台灣嗎？', '各種商品價格多少？', '各種麵條價格多少？', '原味的麵條價格多少？', '原味的麵線價格多少？', '黑芝麻麵條價格多少？', '芋頭麵條價格多少？', '糙米麵條價格多少？', '烏龍茶麵條價格多少？', '金盞花麵條價格多少？', '綠茶麵條價格多少？']\n",
      "type3_A model values: ['我是大呷麵本家的製麵工廠虛擬導覽員。', '非常不好意思，安排行程不是我的專長，你可以問1F的導覽員。', '位於台中市大甲的製作麵條工廠，且有精販賣精美的麵條禮盒。', '這裡是大呷麵本家。', '大呷麵本家的地址是43750台中市大甲區重義二路153號。', '大呷麵本家的電話是04-2686-1026。', '可以用電話聯絡或者是電子郵件聯絡，我們的電話是04-2686-1026，我們的電子郵件是noodlesorigin@gmail.com。', '大呷麵本家的電子郵件是noodlesorigin@gmail.com。', '不是，我們是「大呷麵本家」。', '大呷源自於地名大甲，所以大甲的甲字口部加上家字成為台灣人的用語呷麵，這是結合日本時代的發跡和台灣文化的融合。', '在日本時代都稱為本家大甲。而又因地名不能申請商標，所以在大甲的甲字多個口部，加上麵字，就成為台灣人的用語，呷麵。這是一個結合日本時代的發跡跟台灣文化的融合。', '大呷麵本家的英文名字是Noodles Origin。', 'My name is Noodles Origin。', '大呷麵本家的營業時間是\"週一至週五/9:00~18:00（公司／故事館）；週六、週日/接受團體預約參觀（故事館）\"。', '大呷麵本家的官網是https://www.noodlesorigin.com/index.php?lang=tw。', '我們的產品通過ISO22000&HACCP國際食品安全管制系統認證。', '麵粉、鹽巴和水。', '大呷麵本家麵條是基於台灣古早味改良，現在是用機械化產線製麵。', '製麵工廠將自動攪拌、輾壓、分條、乾燥和計量設備設定標準，實現了大部分生產過程的機械化，以保持高水準的品質與食品安全。', '我們的鹽水間是用來調製鹽水，鹽水的濃度會依照標準化程序調製。', '製麵流程一開始在鹽水間是用來調製鹽水，鹽水的濃度會依照標準化程序調製。', '我們會將調製好的鹽水再與麵粉按比例混合成為麵糰。', '在鹽水調製好後，我們會將調製好的鹽水再與麵粉按比例混合成為麵糰。', '我們會將混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '在麵糰混和好以後倒入製麵機的下料槽，再加入依照口味需求的原料進行混合。', '攪拌麵團的時間是ISO標準化的，根據標準進行正轉和負轉來壓製。', '製麵機會將麵糰分開桿成麵皮，再將兩部分疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分。', '經由將分開成兩部分的麵皮疊在一起壓製成麵餅，並且經過滾輪的持續壓製將厚度變為1公分，確保不會有太薄或太厚的部分。', '透過滾輪輾壓來減少麵皮厚度，確保麵條達到標準厚度，不會變得過厚。', '透過在一開始就用兩片麵皮經過滾輪輾壓，確保麵條達到標準厚度，不會變得過薄。', '我們會將壓製成1公分的麵餅用麵刀依照寬度分條，一共有四種寬度：麵線、麵條、寬麵、最寬的麵。', '在將麵餅壓製成1公分後用麵刀依照寬度分條。', '一共有四種寬度：麵線、麵條、寬麵、最寬的麵。', '分條過程中使用麵刀。', '分條過程中使用麵刀，將壓製成1公分的麵餅用麵刀依照寬度分條。', '分條後的麵條會掛在乾燥架上，送至乾燥室進行乾燥。', '長麵條會掛在乾燥架上，送至乾燥室進行乾燥。', '視當天天氣情況而定，長麵條通常需要在乾燥室中乾燥5個半小時，模擬日曬的時間。', '視當天天氣情況而定，長麵條通常需要在乾燥室中乾燥5個半小時，如果乾燥程度不夠則會繼續乾燥。', '因為我們是依據台灣古早味的手法改良，控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '我們控制溫度以及濕度模擬日曬的環境。', '我們經由控制溫度以及濕度模擬日曬的環境，依照天氣情況調整溫度、濕度以及乾燥時間。', '長麵條的乾燥程度，長麵條水分必須降低至12%。', '長麵條會在乾燥室乾燥使長麵條水分降低至12%，如果乾燥程度不夠則會繼續乾燥。', '如果長麵條的水分含量超過12%，它可能會在包裝後發霉或變質，影響品質。', '乾燥完成的長麵條依照長度進行切分，長度為19到20公分，並且將切分好的半成品麵條捆成1束，通常1束為100公克。', '在乾燥完成的長麵條依照長度進行切分，長度為19到20公分，。', '在依照19到20公分的長度切分好後的麵條捆成1束，通常1束為100公克。', '半成品麵條長度為19到20公分。', '將切分好的半成品麵條捆成1束，通常1束為100公克。', '因為100公克是一般人一餐所需的量。', '綑成一束的半成品麵條經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '在半成品麵條綑綁完成後，經過自動計量機檢測重量是否有達到標準，達到標準後依規格進行封口機封口後包裝。', '半成品麵條經過自動計量機檢測重量是否有達到標準，確保每一束半成品麵條的份量一致。', '要使用自動計量機檢測半成品麵條重量是否有達到標準，確保每一束半成品麵條的份量一致。', '自動計量機檢測半成品麵條重量是否有達到標準，確保每一束半成品麵條的份量一致。', '包裝有量販包裝、禮盒包裝。', '完成封口包裝後會經過金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '在半成品麵條完成封口包裝後會經過金屬檢測機和含水量檢查。', '使用金屬檢測機和含水量檢查進行最後的檢測，確保食品衛生以及食品安全。', '因為金屬檢測器可以用來檢測麵條中是否含有金屬雜質，確保食品的安全。', '成品經過封口、金屬檢測和含水量檢查後，會被放進禮盒內或是使用袋裝，準備出貨。', '在經過封口、金屬檢測和含水量檢查後包裝，有量販包裝、禮盒包裝。。', '我們藉由清潔區分區，成品經過封口機封口後不再接觸外界環境，確保不會有交叉污染。', '我們藉由清潔區分區，成品經過封口機封口後不再接觸外界環境，以防止蟲害問題。', '我們藉由清潔區分區，成品經過封口機封口後不再接觸外界環境，以防止成品遭受汙染。', '工廠內採取清潔區和準清潔區分區的方式，並通過防護設備確保沒有交叉污染。', '清潔區是用來進行包裝的空間，以確保食品衛生以及食品安全。', '包裝在清潔區。', '我們在清潔區包裝。', '準清潔區則是生產製麵的空間，例如鹽水間和乾燥室。', '生產製麵在準清潔區。', '鹽水間在準清潔區。', '製麵機在準清潔區。', '乾燥室在準清潔區。', '分切長麵條在準清潔區。', '麵餅分條在準清潔區。', '工作人員防護裝備有防塵衣、口罩、髮網、鞋套等防護裝備。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，並進行標準化防護操作，以確保食品衛生以及食品安全。', '工作人員需穿戴防塵衣、口罩、髮網、鞋套等防護裝備，進場前有風淋室。', '8種，其中有各式各樣口味的麵條與麵線', '8種，其中有各式各樣口味的麵條與麵線', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '有原味麵條、原味麵線、黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條。', '我們會將鹽水與麵粉混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入大甲芋頭原料進行混合。', '我們會將鹽水與麵粉混和好的麵糰倒入製麵機的下料槽，再加入依照口味需求加入烏龍茶原料進行混合。', '我們的麵條原料來自於台灣當地的優質農產品。', '是的，我們的麵條原料來自於台灣當地的優質農產品。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條都是95元。', '原味的麵條與麵線各90元；黑芝麻麵條、芋頭麵條、糙米麵條、烏龍茶麵條、金盞花麵條、綠茶麵條都是95元。', '原味的麵條是90元。', '原味的麵線是90元。', '黑芝麻麵條是95元。', '芋頭麵條是95元。', '糙米麵條是95元。', '烏龍茶麵條是95元。', '金盞花麵條是95元。', '綠茶麵條是95元。']\n",
      "type3_A length: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:\\\\Serious\\\\Program\\\\Github\\\\noodle_LLM\")\n",
    "\n",
    "dir_test_dataset = \"./training/LLM_eval/testDataset/\"\n",
    "dir_chat_output= \"./training/LLM_eval/chatOutput/\"\n",
    "dir_output = \"./training/LLM_eval/evalOutput/\"\n",
    "\n",
    "# \n",
    "model_candidate = {}\n",
    "for i in model_list:\n",
    "    model_candidate[i] = f\"{dir_chat_output}{i}.csv\"\n",
    "\n",
    "#\n",
    "user_values = {}\n",
    "model_values = {}\n",
    "chat_len = {}\n",
    "\n",
    "for i in type_list:\n",
    "    with open(f\"{dir_test_dataset}{i}.csv\", mode='r', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        # init\n",
    "        user_values[i] = []\n",
    "        model_values[i] = []\n",
    "        chat_len[i] = 0\n",
    "\n",
    "        for row in csv_reader:\n",
    "            user_values[i].append(row['user'])\n",
    "            model_values[i].append(row['model'])\n",
    "    if len(user_values[i]) == len(user_values[i]):\n",
    "        chat_len[i] = len(user_values[i])\n",
    "\n",
    "for i in type_list:\n",
    "    print(f\"{i} user values: {user_values[i]}\")\n",
    "    print(f\"{i} model values: {model_values[i]}\")\n",
    "    print(f\"{i} length: {chat_len[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 測試評估資料集是否有讀取到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': '請介紹綠茶麵條'}\n",
      "{'role': 'user', 'content': '綠茶麵條價格多少？'}\n"
     ]
    }
   ],
   "source": [
    "for i in type_list:    \n",
    "    messages={\"role\": \"user\", \"content\": user_values[i][chat_len[i]-1]}\n",
    "    print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 匯入模型問答csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type2-8-50E64B_A: 大呷麵本家的電子郵件是nta@udnmail.com。請問有什麼我可以幫忙的嗎？\n",
      "lora_type2-128-50E64B_A: 大呷麵本家的電子郵件是noodlesorigin@gmail.com，歡迎您來信洽詢！\n",
      "lora_type2-128-100E64B_A: 大呷麵本家的電子郵件是noodlesorigin@gmail.com。有任何問題都可以發送電子郵件，很高興為您服務！\n",
      "lora_type2-256-50E64B_A: 大呷麵本家的電子郵件是noodlesorigin@gmail.com。很高興為您服務，請問您還有其他問題嗎？\n",
      "lora_type2-256-100E64B_A: 大呷麵本家的電子郵件是noodlesorigin@gmail.com，歡迎您來信詢問！\n",
      "lora_type3-256-100E32B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-100E64B_A_old: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-100E64B_2_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-100E128B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-150E32B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-200E32B_A: 大呷麵本家的電話是04-2686-1026。很高興為您服務！請問您是誰？\n",
      "lora_type3-256-200E64B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-200E128B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-200E128B_2_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-300E32B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-300E64B_A: 大呷麵本家的電話是04-2686-1026。\n",
      "lora_type3-256-300E128B_A: 大呷麵本家的電話是04-2686-1026。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_answer={}\n",
    "latency_t = {}\n",
    "\n",
    "# 動態創建變數並存儲 Model's Answer\n",
    "for key, file_path in model_candidate.items():\n",
    "    df = pd.read_csv(f'{file_path}')\n",
    "\n",
    "    # 提取 \"Model's Answer\" 列並轉換為列表\n",
    "    real_answer[key] = df[\"Model's Answer\"].tolist()\n",
    "    latency_t[key] = df[\"Latency\"].tolist()\n",
    "\n",
    "# 確認變數是否正確創建和存儲\n",
    "for i in real_answer:\n",
    "    print(f\"{i}: {real_answer[i][5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 評估 ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type2-8-50E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.4634, 'p': 0.2986, 'f': 0.381}\n",
      "rouge-2: {'r': 0.21, 'p': 0.1267, 'f': 0.1684}\n",
      "rouge-l: {'r': 0.4173, 'p': 0.2452, 'f': 0.3313}\n",
      "\n",
      "Average f1-score: 0.2936\n",
      "---------------------------------------------------------\n",
      "lora_type2-128-50E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.6276, 'p': 0.3076, 'f': 0.4676}\n",
      "rouge-2: {'r': 0.3727, 'p': 0.1514, 'f': 0.2621}\n",
      "rouge-l: {'r': 0.5853, 'p': 0.2116, 'f': 0.3984}\n",
      "\n",
      "Average f1-score: 0.376\n",
      "---------------------------------------------------------\n",
      "lora_type2-128-100E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.6458, 'p': 0.2332, 'f': 0.4395}\n",
      "rouge-2: {'r': 0.3838, 'p': 0.11, 'f': 0.2469}\n",
      "rouge-l: {'r': 0.5851, 'p': 0.1553, 'f': 0.3702}\n",
      "\n",
      "Average f1-score: 0.3522\n",
      "---------------------------------------------------------\n",
      "lora_type2-256-50E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.6563, 'p': 0.4005, 'f': 0.5284}\n",
      "rouge-2: {'r': 0.4601, 'p': 0.2351, 'f': 0.3476}\n",
      "rouge-l: {'r': 0.6171, 'p': 0.3116, 'f': 0.4644}\n",
      "\n",
      "Average f1-score: 0.4468\n",
      "---------------------------------------------------------\n",
      "lora_type2-256-100E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.7395, 'p': 0.5054, 'f': 0.6224}\n",
      "rouge-2: {'r': 0.5589, 'p': 0.3566, 'f': 0.4578}\n",
      "rouge-l: {'r': 0.7157, 'p': 0.4191, 'f': 0.5674}\n",
      "\n",
      "Average f1-score: 0.5492\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-100E32B_A Average Scores:\n",
      "rouge-1: {'r': 0.7504, 'p': 0.6435, 'f': 0.6969}\n",
      "rouge-2: {'r': 0.6091, 'p': 0.5194, 'f': 0.5643}\n",
      "rouge-l: {'r': 0.7238, 'p': 0.5877, 'f': 0.6557}\n",
      "\n",
      "Average f1-score: 0.639\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-100E64B_A_old Average Scores:\n",
      "rouge-1: {'r': 0.7278, 'p': 0.5828, 'f': 0.6553}\n",
      "rouge-2: {'r': 0.5481, 'p': 0.4366, 'f': 0.4924}\n",
      "rouge-l: {'r': 0.6849, 'p': 0.5172, 'f': 0.601}\n",
      "\n",
      "Average f1-score: 0.5829\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-100E64B_2_A Average Scores:\n",
      "rouge-1: {'r': 0.7615, 'p': 0.6782, 'f': 0.7199}\n",
      "rouge-2: {'r': 0.5874, 'p': 0.5275, 'f': 0.5574}\n",
      "rouge-l: {'r': 0.7184, 'p': 0.6178, 'f': 0.6681}\n",
      "\n",
      "Average f1-score: 0.6485\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-100E128B_A Average Scores:\n",
      "rouge-1: {'r': 0.7699, 'p': 0.6321, 'f': 0.701}\n",
      "rouge-2: {'r': 0.6023, 'p': 0.4935, 'f': 0.5479}\n",
      "rouge-l: {'r': 0.7154, 'p': 0.5705, 'f': 0.6429}\n",
      "\n",
      "Average f1-score: 0.6306\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-150E32B_A Average Scores:\n",
      "rouge-1: {'r': 0.7704, 'p': 0.6878, 'f': 0.7291}\n",
      "rouge-2: {'r': 0.6154, 'p': 0.5461, 'f': 0.5808}\n",
      "rouge-l: {'r': 0.7381, 'p': 0.6436, 'f': 0.6909}\n",
      "\n",
      "Average f1-score: 0.6669\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-200E32B_A Average Scores:\n",
      "rouge-1: {'r': 0.7497, 'p': 0.4765, 'f': 0.6131}\n",
      "rouge-2: {'r': 0.5836, 'p': 0.358, 'f': 0.4708}\n",
      "rouge-l: {'r': 0.7098, 'p': 0.403, 'f': 0.5564}\n",
      "\n",
      "Average f1-score: 0.5468\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-200E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.7814, 'p': 0.6468, 'f': 0.7141}\n",
      "rouge-2: {'r': 0.6309, 'p': 0.5215, 'f': 0.5762}\n",
      "rouge-l: {'r': 0.7451, 'p': 0.5976, 'f': 0.6713}\n",
      "\n",
      "Average f1-score: 0.6539\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-200E128B_A Average Scores:\n",
      "rouge-1: {'r': 0.7721, 'p': 0.7293, 'f': 0.7507}\n",
      "rouge-2: {'r': 0.6443, 'p': 0.6024, 'f': 0.6234}\n",
      "rouge-l: {'r': 0.7425, 'p': 0.6932, 'f': 0.7179}\n",
      "\n",
      "Average f1-score: 0.6973\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-200E128B_2_A Average Scores:\n",
      "rouge-1: {'r': 0.7721, 'p': 0.7293, 'f': 0.7507}\n",
      "rouge-2: {'r': 0.6443, 'p': 0.6024, 'f': 0.6234}\n",
      "rouge-l: {'r': 0.7425, 'p': 0.6932, 'f': 0.7179}\n",
      "\n",
      "Average f1-score: 0.6973\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-300E32B_A Average Scores:\n",
      "rouge-1: {'r': 0.7081, 'p': 0.6301, 'f': 0.6691}\n",
      "rouge-2: {'r': 0.529, 'p': 0.4703, 'f': 0.4997}\n",
      "rouge-l: {'r': 0.6656, 'p': 0.5808, 'f': 0.6232}\n",
      "\n",
      "Average f1-score: 0.5973\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-300E64B_A Average Scores:\n",
      "rouge-1: {'r': 0.8071, 'p': 0.4743, 'f': 0.6407}\n",
      "rouge-2: {'r': 0.63, 'p': 0.3551, 'f': 0.4925}\n",
      "rouge-l: {'r': 0.759, 'p': 0.4005, 'f': 0.5797}\n",
      "\n",
      "Average f1-score: 0.571\n",
      "---------------------------------------------------------\n",
      "lora_type3-256-300E128B_A Average Scores:\n",
      "rouge-1: {'r': 0.7539, 'p': 0.6915, 'f': 0.7227}\n",
      "rouge-2: {'r': 0.5962, 'p': 0.5521, 'f': 0.5741}\n",
      "rouge-l: {'r': 0.715, 'p': 0.6456, 'f': 0.6803}\n",
      "\n",
      "Average f1-score: 0.659\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cc = OpenCC('t2s')\n",
    "rouge = Rouge()\n",
    "def evaluate_ROUGE(model_values, model_ans, model_name, scores_list, count):\n",
    "    \n",
    "    for i in range(count):\n",
    "        completion = model_ans[i]\n",
    "        reference = model_values[i]\n",
    "\n",
    "        reference = cc.convert(reference)\n",
    "        reference = '/ '.join(jieba.cut(reference, cut_all=False))\n",
    "        \n",
    "        generated_answer = completion\n",
    "        generated_answer = cc.convert(generated_answer)\n",
    "        generated_answer = '/ '.join(jieba.cut(generated_answer, cut_all=False))\n",
    "        \n",
    "        score = rouge.get_scores(generated_answer, reference)\n",
    "        scores_list.append(score)\n",
    "        \n",
    "    avg_scores = {'rouge-1': {'r': 0, 'p': 0, 'f': 0},\n",
    "        'rouge-2': {'r': 0, 'p': 0, 'f': 0},\n",
    "        'rouge-l': {'r': 0, 'p': 0, 'f': 0}}\n",
    "\n",
    "    num_instances = len(scores_list)\n",
    "    for instance_scores in scores_list:\n",
    "        for metric, metrics_scores in instance_scores[0].items():\n",
    "            for score_type, value in metrics_scores.items():\n",
    "                if score_type != 'f':  # 暫時跳過 'f' 分數\n",
    "                    avg_scores[metric][score_type] += value / num_instances\n",
    "\n",
    "    # 根據 (r + p) / 2 來計算新的 'f' 分數，並四捨五入到小數點第四位\n",
    "    for metric, metrics_scores in avg_scores.items():\n",
    "        r = metrics_scores['r']\n",
    "        p = metrics_scores['p']\n",
    "        avg_scores[metric]['f'] = round((r + p) / 2, 4)\n",
    "        avg_scores[metric]['r'] = round(r, 4)\n",
    "        avg_scores[metric]['p'] = round(p, 4)\n",
    "\n",
    "    # 計算 rouge-1, rouge-2, rouge-l 的 f 分數平均值\n",
    "    f_score_avg = (avg_scores['rouge-1']['f'] + avg_scores['rouge-2']['f'] + avg_scores['rouge-l']['f']) / 3\n",
    "    f_score_avg = round(f_score_avg, 4)\n",
    "    tmp = []\n",
    "\n",
    "    print(model_name,\"Average Scores:\")\n",
    "    for metric, metrics_scores in avg_scores.items():\n",
    "        print(f\"{metric}: {metrics_scores}\")\n",
    "        tmp.append(metrics_scores['f'])\n",
    "    print(f\"\\nAverage f1-score: {f_score_avg}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "\n",
    "   \n",
    "    ori_data[model_name] = (tmp[0], tmp[1], tmp[2], f_score_avg)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "scores_dict = {}\n",
    "for i in real_answer:\n",
    "    scores_dict[i] = []\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}ROUGE_A.csv'):\n",
    "    with open(f'{dir_output}ROUGE_A.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = (row[\"rouge-1\"],row[\"rouge-2\"],row[\"rouge-l\"],row[\"Average\"])\n",
    "\n",
    "with open(f'{dir_output}ROUGE_A.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"rouge-1\", \"rouge-2\",\"rouge-l\",\"Average\"]) \n",
    "    for i in real_answer:\n",
    "        if \"type2\" in i:\n",
    "            std_answer = model_values[\"type2_A\"]\n",
    "            c_len = chat_len[\"type2_A\"]\n",
    "        elif \"type3\" in i:\n",
    "            std_answer = model_values[\"type3_A\"]\n",
    "            c_len = chat_len[\"type3_A\"]\n",
    "        evaluate_ROUGE(std_answer, real_answer[i], i, scores_dict[i], c_len)\n",
    "\n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i][0], ori_data[i][1], ori_data[i][2], ori_data[i][3]])\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 評估 Sentence-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type2-8-50E64B_A SentenceTransformer Semantic Similarity score: 0.5224\n",
      "lora_type2-128-50E64B_A SentenceTransformer Semantic Similarity score: 0.5867\n",
      "lora_type2-128-100E64B_A SentenceTransformer Semantic Similarity score: 0.539\n",
      "lora_type2-256-50E64B_A SentenceTransformer Semantic Similarity score: 0.6474\n",
      "lora_type2-256-100E64B_A SentenceTransformer Semantic Similarity score: 0.7113\n",
      "lora_type3-256-100E32B_A SentenceTransformer Semantic Similarity score: 0.7574\n",
      "lora_type3-256-100E64B_A_old SentenceTransformer Semantic Similarity score: 0.7233\n",
      "lora_type3-256-100E64B_2_A SentenceTransformer Semantic Similarity score: 0.7741\n",
      "lora_type3-256-100E128B_A SentenceTransformer Semantic Similarity score: 0.7762\n",
      "lora_type3-256-150E32B_A SentenceTransformer Semantic Similarity score: 0.7858\n",
      "lora_type3-256-200E32B_A SentenceTransformer Semantic Similarity score: 0.6715\n",
      "lora_type3-256-200E64B_A SentenceTransformer Semantic Similarity score: 0.7758\n",
      "lora_type3-256-200E128B_A SentenceTransformer Semantic Similarity score: 0.8035\n",
      "lora_type3-256-200E128B_2_A SentenceTransformer Semantic Similarity score: 0.8035\n",
      "lora_type3-256-300E32B_A SentenceTransformer Semantic Similarity score: 0.7126\n",
      "lora_type3-256-300E64B_A SentenceTransformer Semantic Similarity score: 0.7056\n",
      "lora_type3-256-300E128B_A SentenceTransformer Semantic Similarity score: 0.7754\n"
     ]
    }
   ],
   "source": [
    "ST_model = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
    "\n",
    "\n",
    "def evaluate_ST(model_values, model_ans, model_name, scores_dict, count):\n",
    "    for i in range(0, count):\n",
    "        completion = model_ans[i]\n",
    "        reference = model_values[i]\n",
    "        generated_answer = completion\n",
    "        \n",
    "        e_q = ST_model.encode(generated_answer)        \n",
    "        embeddings = ST_model.encode(reference)       \n",
    "        sym = float(util.pytorch_cos_sim(e_q, embeddings).detach().numpy()[0][0])\n",
    "        score = sym\n",
    "        scores_dict.append(score)\n",
    "        \n",
    "    avg_scores = round(sum(scores_dict)/len(scores_dict), 4)\n",
    "    print(model_name,\"SentenceTransformer Semantic Similarity score:\", avg_scores)\n",
    "\n",
    "    ori_data[model_name] = avg_scores\n",
    "\n",
    "\n",
    "scores_dict = {}\n",
    "for i in real_answer:\n",
    "    scores_dict[i] = []\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}ST_A.csv'):\n",
    "    with open(f'{dir_output}ST_A.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = (row[\"ST\"])\n",
    "\n",
    "with open(f'{dir_output}ST_A.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"ST\"]) \n",
    "    for i in real_answer:\n",
    "        if \"type2\" in i:\n",
    "            std_answer = model_values[\"type2_A\"]\n",
    "            c_len = chat_len[\"type2_A\"]\n",
    "        elif \"type3\" in i:\n",
    "            std_answer = model_values[\"type3_A\"]\n",
    "            c_len = chat_len[\"type3_A\"]\n",
    "        evaluate_ST(std_answer, real_answer[i], i, scores_dict[i], c_len)\n",
    "\n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 評估 BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Serious\\Program\\venvs\\noodle_LLM\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Serious\\Program\\venvs\\noodle_LLM\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Serious\\Program\\venvs\\noodle_LLM\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type2-8-50E64B_A BLEU-1 score: 0.3838\n",
      "lora_type2-8-50E64B_A BLEU-2 score: 0.267\n",
      "lora_type2-8-50E64B_A BLEU-3 score: 0.1996\n",
      "lora_type2-8-50E64B_A BLEU-4 score: 0.1511\n",
      "lora_type2-8-50E64B_A BLEU score: 0.2275\n",
      "-----------------------------------------------------\n",
      "lora_type2-128-50E64B_A BLEU-1 score: 0.3062\n",
      "lora_type2-128-50E64B_A BLEU-2 score: 0.2408\n",
      "lora_type2-128-50E64B_A BLEU-3 score: 0.1941\n",
      "lora_type2-128-50E64B_A BLEU-4 score: 0.159\n",
      "lora_type2-128-50E64B_A BLEU score: 0.212\n",
      "-----------------------------------------------------\n",
      "lora_type2-128-100E64B_A BLEU-1 score: 0.2391\n",
      "lora_type2-128-100E64B_A BLEU-2 score: 0.1863\n",
      "lora_type2-128-100E64B_A BLEU-3 score: 0.1501\n",
      "lora_type2-128-100E64B_A BLEU-4 score: 0.123\n",
      "lora_type2-128-100E64B_A BLEU score: 0.1641\n",
      "-----------------------------------------------------\n",
      "lora_type2-256-50E64B_A BLEU-1 score: 0.3726\n",
      "lora_type2-256-50E64B_A BLEU-2 score: 0.3069\n",
      "lora_type2-256-50E64B_A BLEU-3 score: 0.262\n",
      "lora_type2-256-50E64B_A BLEU-4 score: 0.2242\n",
      "lora_type2-256-50E64B_A BLEU score: 0.279\n",
      "-----------------------------------------------------\n",
      "lora_type2-256-100E64B_A BLEU-1 score: 0.4848\n",
      "lora_type2-256-100E64B_A BLEU-2 score: 0.4294\n",
      "lora_type2-256-100E64B_A BLEU-3 score: 0.3848\n",
      "lora_type2-256-100E64B_A BLEU-4 score: 0.3491\n",
      "lora_type2-256-100E64B_A BLEU score: 0.4035\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-100E32B_A BLEU-1 score: 0.6307\n",
      "lora_type3-256-100E32B_A BLEU-2 score: 0.5645\n",
      "lora_type3-256-100E32B_A BLEU-3 score: 0.5265\n",
      "lora_type3-256-100E32B_A BLEU-4 score: 0.4978\n",
      "lora_type3-256-100E32B_A BLEU score: 0.5454\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-100E64B_A_old BLEU-1 score: 0.5891\n",
      "lora_type3-256-100E64B_A_old BLEU-2 score: 0.5186\n",
      "lora_type3-256-100E64B_A_old BLEU-3 score: 0.4727\n",
      "lora_type3-256-100E64B_A_old BLEU-4 score: 0.4377\n",
      "lora_type3-256-100E64B_A_old BLEU score: 0.4943\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-100E64B_2_A BLEU-1 score: 0.6695\n",
      "lora_type3-256-100E64B_2_A BLEU-2 score: 0.602\n",
      "lora_type3-256-100E64B_2_A BLEU-3 score: 0.55\n",
      "lora_type3-256-100E64B_2_A BLEU-4 score: 0.5099\n",
      "lora_type3-256-100E64B_2_A BLEU score: 0.5711\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-100E128B_A BLEU-1 score: 0.6371\n",
      "lora_type3-256-100E128B_A BLEU-2 score: 0.5756\n",
      "lora_type3-256-100E128B_A BLEU-3 score: 0.5294\n",
      "lora_type3-256-100E128B_A BLEU-4 score: 0.4948\n",
      "lora_type3-256-100E128B_A BLEU score: 0.5483\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-150E32B_A BLEU-1 score: 0.6697\n",
      "lora_type3-256-150E32B_A BLEU-2 score: 0.6048\n",
      "lora_type3-256-150E32B_A BLEU-3 score: 0.5583\n",
      "lora_type3-256-150E32B_A BLEU-4 score: 0.5224\n",
      "lora_type3-256-150E32B_A BLEU score: 0.5775\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-200E32B_A BLEU-1 score: 0.4521\n",
      "lora_type3-256-200E32B_A BLEU-2 score: 0.4057\n",
      "lora_type3-256-200E32B_A BLEU-3 score: 0.3723\n",
      "lora_type3-256-200E32B_A BLEU-4 score: 0.3471\n",
      "lora_type3-256-200E32B_A BLEU score: 0.3852\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-200E64B_A BLEU-1 score: 0.6478\n",
      "lora_type3-256-200E64B_A BLEU-2 score: 0.5926\n",
      "lora_type3-256-200E64B_A BLEU-3 score: 0.5508\n",
      "lora_type3-256-200E64B_A BLEU-4 score: 0.517\n",
      "lora_type3-256-200E64B_A BLEU score: 0.5675\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-200E128B_A BLEU-1 score: 0.7248\n",
      "lora_type3-256-200E128B_A BLEU-2 score: 0.6663\n",
      "lora_type3-256-200E128B_A BLEU-3 score: 0.6235\n",
      "lora_type3-256-200E128B_A BLEU-4 score: 0.5921\n",
      "lora_type3-256-200E128B_A BLEU score: 0.639\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-200E128B_2_A BLEU-1 score: 0.7248\n",
      "lora_type3-256-200E128B_2_A BLEU-2 score: 0.6663\n",
      "lora_type3-256-200E128B_2_A BLEU-3 score: 0.6235\n",
      "lora_type3-256-200E128B_2_A BLEU-4 score: 0.5921\n",
      "lora_type3-256-200E128B_2_A BLEU score: 0.639\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-300E32B_A BLEU-1 score: 0.6404\n",
      "lora_type3-256-300E32B_A BLEU-2 score: 0.5556\n",
      "lora_type3-256-300E32B_A BLEU-3 score: 0.5043\n",
      "lora_type3-256-300E32B_A BLEU-4 score: 0.4697\n",
      "lora_type3-256-300E32B_A BLEU score: 0.5244\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-300E64B_A BLEU-1 score: 0.4335\n",
      "lora_type3-256-300E64B_A BLEU-2 score: 0.3953\n",
      "lora_type3-256-300E64B_A BLEU-3 score: 0.3633\n",
      "lora_type3-256-300E64B_A BLEU-4 score: 0.3366\n",
      "lora_type3-256-300E64B_A BLEU score: 0.3762\n",
      "-----------------------------------------------------\n",
      "lora_type3-256-300E128B_A BLEU-1 score: 0.6817\n",
      "lora_type3-256-300E128B_A BLEU-2 score: 0.6169\n",
      "lora_type3-256-300E128B_A BLEU-3 score: 0.5698\n",
      "lora_type3-256-300E128B_A BLEU-4 score: 0.5355\n",
      "lora_type3-256-300E128B_A BLEU score: 0.5913\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_BLEU(model_values, model_ans, model_name, scores_dict, count):\n",
    "\n",
    "    \n",
    "    candidate_list = list()\n",
    "    reference_list = list()\n",
    "    \n",
    "    bleu_1_scores = []\n",
    "    bleu_2_scores = []\n",
    "    bleu_3_scores = []\n",
    "    bleu_4_scores = []\n",
    "    bleu_avg_scores = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, count):\n",
    "        completion = model_ans[i]\n",
    "        reference = model_values[i]     \n",
    "        \n",
    "        # 將生成的句子逐字切分\n",
    "        generated_answer_sepWords = ' '.join(jieba.cut(completion))\n",
    "        generated_answer = list(generated_answer_sepWords)\n",
    "        candidate_list.append(generated_answer)\n",
    "    \n",
    "        # 將參考句子逐字切分\n",
    "        reference_sepWords = ' '.join(jieba.cut(reference))\n",
    "        reference_answer = list(reference_sepWords)\n",
    "        reference_list.append([reference_answer])\n",
    "\n",
    "        bleu_1_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(1, 0, 0, 0))\n",
    "        bleu_2_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(0, 1, 0, 0))\n",
    "        bleu_3_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(0, 0, 1, 0))\n",
    "        bleu_4_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i], weights=(0, 0, 0, 1))\n",
    "        bleu_avg_score = sentence_bleu(references=reference_list[i], hypothesis=candidate_list[i])\n",
    "        \n",
    "        bleu_1_scores.append(bleu_1_score)\n",
    "        bleu_2_scores.append(bleu_2_score)\n",
    "        bleu_3_scores.append(bleu_3_score)\n",
    "        bleu_4_scores.append(bleu_4_score)\n",
    "        bleu_avg_scores.append(bleu_avg_score)\n",
    "        \n",
    "    avg_bleu_1 = round(sum(bleu_1_scores) / len(bleu_1_scores), 4)\n",
    "    avg_bleu_2 = round(sum(bleu_2_scores) / len(bleu_2_scores), 4)\n",
    "    avg_bleu_3 = round(sum(bleu_3_scores) / len(bleu_3_scores), 4)\n",
    "    avg_bleu_4 = round(sum(bleu_4_scores) / len(bleu_4_scores), 4)\n",
    "    avg_bleu_avg = round(sum(bleu_avg_scores) / len(bleu_avg_scores), 4)\n",
    "    print(f\"{model_name} BLEU-1 score: {avg_bleu_1}\")\n",
    "    print(f\"{model_name} BLEU-2 score: {avg_bleu_2}\")\n",
    "    print(f\"{model_name} BLEU-3 score: {avg_bleu_3}\")\n",
    "    print(f\"{model_name} BLEU-4 score: {avg_bleu_4}\")\n",
    "    print(f\"{model_name} BLEU score: {avg_bleu_avg}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    ori_data[model_name] = avg_bleu_avg\n",
    "\n",
    "\n",
    "scores_dict = {}\n",
    "for i in real_answer:\n",
    "    scores_dict[i] = []\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}BLEU_A.csv'):\n",
    "    with open(f'{dir_output}BLEU_A.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = (row[\"BLEU\"])\n",
    "\n",
    "with open(f'{dir_output}BLEU_A.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"BLEU\"]) \n",
    "    for i in real_answer:\n",
    "        if \"type2\" in i:\n",
    "            std_answer = model_values[\"type2_A\"]\n",
    "            c_len = chat_len[\"type2_A\"]\n",
    "        elif \"type3\" in i:\n",
    "            std_answer = model_values[\"type3_A\"]\n",
    "            c_len = chat_len[\"type3_A\"]\n",
    "        evaluate_BLEU(std_answer, real_answer[i], i, scores_dict[i], c_len)\n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 評估延遲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_type2-8-50E64B_A latency: 5.165 s\n",
      "lora_type2-128-50E64B_A latency: 9.513 s\n",
      "lora_type2-128-100E64B_A latency: 10.175 s\n",
      "lora_type2-256-50E64B_A latency: 12.146 s\n",
      "lora_type2-256-100E64B_A latency: 7.568 s\n",
      "lora_type3-256-100E32B_A latency: 4.163 s\n",
      "lora_type3-256-100E64B_A_old latency: 5.433 s\n",
      "lora_type3-256-100E64B_2_A latency: 4.91 s\n",
      "lora_type3-256-100E128B_A latency: 4.806 s\n",
      "lora_type3-256-150E32B_A latency: 6.914 s\n",
      "lora_type3-256-200E32B_A latency: 7.811 s\n",
      "lora_type3-256-200E64B_A latency: 4.604 s\n",
      "lora_type3-256-200E128B_A latency: 3.877 s\n",
      "lora_type3-256-200E128B_2_A latency: 3.897 s\n",
      "lora_type3-256-300E32B_A latency: 4.492 s\n",
      "lora_type3-256-300E64B_A latency: 9.34 s\n",
      "lora_type3-256-300E128B_A latency: 4.066 s\n"
     ]
    }
   ],
   "source": [
    "def evaluate_latency(model_name):\n",
    "    average = sum(latency_t[model_name]) / len(latency_t[model_name])\n",
    "    average = round(average, 3)\n",
    "    print(f\"{model_name} latency: {average} s\")\n",
    "\n",
    "    ori_data[model_name] = average\n",
    "\n",
    "\n",
    "\n",
    "ori_data = {}\n",
    "if os.path.isfile(f'{dir_output}LATENCY_A.csv'):\n",
    "    with open(f'{dir_output}LATENCY_A.csv', mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            ori_data[row[\"model_name\"]] = row[\"LATENCY\"]\n",
    "\n",
    "with open(f'{dir_output}LATENCY_A.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"model_name\", \"LATENCY\"])\n",
    "    for i in model_list:\n",
    "        evaluate_latency(i)\n",
    "    \n",
    "    for i in ori_data:\n",
    "        writer.writerow([i, ori_data[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noodle_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
